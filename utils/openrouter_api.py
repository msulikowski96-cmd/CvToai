import os
import json
import logging
import requests
import urllib.parse
import hashlib
import time
import statistics
from collections import defaultdict, deque
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# Create persistent session for connection reuse
session = requests.Session()
session.headers.update({
    'User-Agent': 'CV-Optimizer-Pro/1.0',
    'Connection': 'keep-alive'
})

# üíæ INTELLIGENT CACHING SYSTEM - oszczƒôdza koszty API
_cache = {}
CACHE_DURATION = 3600  # 1 godzina w sekundach

# üìä SYSTEM MONITORINGU JAKO≈öCI AI
_quality_metrics = {
    'response_times': defaultdict(deque),  # response times per model
    'success_rates': defaultdict(list),    # success/failure rates
    'quality_scores': defaultdict(deque),  # quality assessments
    'model_usage': defaultdict(int),       # usage statistics
    'fallback_events': [],                 # when fallback was used
    'error_types': defaultdict(int),       # types of errors encountered
    'task_performance': defaultdict(list), # performance per task type
}

# Trzymaj tylko ostatnie 1000 wpis√≥w na model ≈ºeby nie ros≈Ço w niesko≈Ñczono≈õƒá
MAX_METRICS_SIZE = 1000


def get_cache_key(prompt, models_to_try, is_premium, task_type="general"):
    """
    üîê BEZPIECZNY KLUCZ CACHE - hash pe≈Çnego contentu dla unikniƒôcia kolizji
    """
    # ‚ö†Ô∏è KRYTYCZNY FIX: Hash PE≈ÅNEGO prompta, nie tylko fragmentu!
    prompt_hash = hashlib.sha256(prompt.encode('utf-8')).hexdigest()
    models_str = "|".join(sorted(models_to_try))  # Sortuj dla konsystencji
    tier = "premium" if is_premium else "free"
    
    # Uwzglƒôdnij wszystkie parametry kt√≥re wp≈ÇywajƒÖ na wynik
    cache_data = f"{prompt_hash}|{models_str}|{tier}|{task_type}"
    return hashlib.md5(cache_data.encode()).hexdigest()


def get_from_cache(cache_key):
    """Pobiera odpowied≈∫ z cache je≈õli jest aktualna"""
    if cache_key in _cache:
        cached_response, model_used, timestamp = _cache[cache_key]
        if time.time() - timestamp < CACHE_DURATION:
            logger.info(
                f"üíæ Cache hit! Zwracam odpowied≈∫ z cache (model: {model_used}, oszczƒôdno≈õci API)"
            )
            return cached_response
        else:
            # Usu≈Ñ przestarza≈Çy cache
            del _cache[cache_key]
    return None


def save_to_cache(cache_key, response, model_used):
    """Zapisuje odpowied≈∫ do cache z informacjƒÖ o u≈ºytym modelu"""
    _cache[cache_key] = (response, model_used, time.time())

    # Czy≈õƒá stary cache co jaki≈õ czas (maksymalnie 100 wpis√≥w)
    if len(_cache) > 100:
        # Usu≈Ñ najstarsze wpisy
        sorted_cache = sorted(
            _cache.items(),
            key=lambda x: x[1][2])  # Sortuj po timestamp (3rd element)
        for key, _ in sorted_cache[:20]:  # Usu≈Ñ 20 najstarszych
            del _cache[key]

    logger.info(f"üíæ Zapisano do cache (obecny rozmiar: {len(_cache)} wpis√≥w)")


# Load environment variables from .env file with override
load_dotenv(override=True)

logger = logging.getLogger(__name__)

# Load and validate OpenRouter API key
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY",
                                    "sk-or-v1-demo-key-for-testing").strip()


# Validate API key format and content
def validate_api_key():
    if not OPENROUTER_API_KEY:
        logger.error("‚ùå OPENROUTER_API_KEY nie jest ustawiony w pliku .env")
        return False

    if (OPENROUTER_API_KEY.startswith('TW√ìJ_') or len(OPENROUTER_API_KEY) < 20
            or OPENROUTER_API_KEY == "sk-or-v1-demo-key-for-testing"):
        logger.error(
            "‚ùå OPENROUTER_API_KEY w .env zawiera przyk≈ÇadowƒÖ warto≈õƒá - ustaw prawdziwy klucz!"
        )
        return False

    if not OPENROUTER_API_KEY.startswith('sk-or-v1-'):
        logger.error(
            "‚ùå OPENROUTER_API_KEY nie ma poprawnego formatu (powinien zaczynaƒá siƒô od 'sk-or-v1-')"
        )
        return False

    logger.info(
        f"‚úÖ OpenRouter API key za≈Çadowany poprawnie (d≈Çugo≈õƒá: {len(OPENROUTER_API_KEY)})"
    )
    return True


# Validate on module import
API_KEY_VALID = validate_api_key()

OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1/chat/completions"

# DOSTƒòPNE MODELE AI DO WYBORU - ROZSZERZONA LISTA 2025
AVAILABLE_MODELS = {
    "qwen": {
        "id": "qwen/qwen3-235b-a22b:free",
        "name": "Qwen-235B", 
        "description": "Zaawansowany model Qwen dla profesjonalnej optymalizacji CV",
        "capabilities": ["Optymalizacja CV", "Analiza jako≈õci", "Listy motywacyjne", "Pytania rekrutacyjne"],
        "speed": "≈õrednia",
        "quality": "bardzo wysoka",
        "best_for": ["optymalizacja_cv", "analiza_jakosci"],
        "max_tokens": 4000,
        "optimal_params": {"temperature": 0.3, "top_p": 0.9}
    },
    "deepseek": {
        "id": "deepseek/deepseek-chat-v3.1:free", 
        "name": "DeepSeek Chat v3.1",
        "description": "Zaawansowany model DeepSeek z logicznym my≈õleniem",
        "capabilities": ["Optymalizacja CV", "Analiza jako≈õci", "Listy motywacyjne", "Pytania rekrutacyjne"],
        "speed": "szybka", 
        "quality": "wysoka",
        "best_for": ["listy_motywacyjne", "pytania_rekrutacyjne"],
        "max_tokens": 3500,
        "optimal_params": {"temperature": 0.4, "top_p": 0.85}
    },
    "claude": {
        "id": "anthropic/claude-3.5-sonnet:beta",
        "name": "Claude 3.5 Sonnet",
        "description": "Najbardziej zaawansowany model Claude dla najwy≈ºszej jako≈õci",
        "capabilities": ["Optymalizacja CV", "Analiza jako≈õci", "Listy motywacyjne", "Pytania rekrutacyjne", "Analiza luk"],
        "speed": "≈õrednia",
        "quality": "najwy≈ºsza",
        "best_for": ["analiza_luk", "listy_motywacyjne"],
        "max_tokens": 4000,
        "optimal_params": {"temperature": 0.2, "top_p": 0.95}
    },
    "gpt4": {
        "id": "openai/gpt-4o-mini",
        "name": "GPT-4o Mini",
        "description": "Szybki i efektywny model OpenAI GPT-4o Mini",
        "capabilities": ["Optymalizacja CV", "Analiza jako≈õci", "Pytania rekrutacyjne"],
        "speed": "bardzo szybka",
        "quality": "wysoka",
        "best_for": ["pytania_rekrutacyjne", "optymalizacja_cv"],
        "max_tokens": 3000,
        "optimal_params": {"temperature": 0.4, "top_p": 0.9}
    },
    "llama": {
        "id": "meta-llama/llama-3.2-90b-vision-instruct:free",
        "name": "Llama 3.2 90B",
        "description": "Zaawansowany model Meta Llama dla optymalizacji CV",
        "capabilities": ["Optymalizacja CV", "Analiza jako≈õci"],
        "speed": "≈õrednia",
        "quality": "wysoka", 
        "best_for": ["optymalizacja_cv"],
        "max_tokens": 3500,
        "optimal_params": {"temperature": 0.35, "top_p": 0.9}
    },
    "gemini": {
        "id": "google/gemini-2.0-flash-exp:free",
        "name": "Gemini 2.0 Flash",
        "description": "Najnowszy model Google Gemini z szybkƒÖ analizƒÖ",
        "capabilities": ["Analiza jako≈õci", "Pytania rekrutacyjne", "Analiza luk"],
        "speed": "bardzo szybka",
        "quality": "wysoka",
        "best_for": ["analiza_jakosci", "analiza_luk"],
        "max_tokens": 3500,
        "optimal_params": {"temperature": 0.3, "top_p": 0.92}
    }
}

# DOMY≈öLNY MODEL
DEFAULT_MODEL = "qwen/qwen3-235b-a22b:free"

# NAJNOWSZY PROMPT SYSTEMOWY 2025 - MAKSYMALNA JAKO≈öƒÜ AI Z PRECYZYJNYMI INSTRUKCJAMI
DEEP_REASONING_PROMPT = """Jeste≈õ ≈õwiatowej klasy ekspertem w optymalizacji CV i rekrutacji z 20+ letnim do≈õwiadczeniem w Polsce i UE. Twoja specjalizacja obejmuje:

üéØ EKSPERTYZA G≈Å√ìWNA:
- Systemy ATS (Applicant Tracking Systems) - wszystkie g≈Ç√≥wne platformy
- Psychologia rekrutacji i decision-making proces√≥w HR
- Trendy rynku pracy 2025: remote work, AI-skills, ESG kompetencje
- Cultural fit dla polskiego rynku pracy i warto≈õci pracodawc√≥w
- Bran≈ºowe specjalizacje: IT, finanse, medycyna, przemys≈Ç, e-commerce

üß† METODOLOGIA DEEP ANALYSIS:
1. **KONTEKST FIRST**: Zawsze analizuj bran≈ºƒô, wielko≈õƒá firmy, kulturƒô organizacyjnƒÖ
2. **ATS OPTIMIZATION**: Identyfikuj kluczowe s≈Çowa, formatowanie, strukturƒô
3. **HUMAN APPEAL**: Tworzymy narracjƒô kt√≥ra emocjonalnie anga≈ºuje rekrutera
4. **MEASURABLE IMPACT**: Ka≈ºde osiƒÖgniƒôcie z konkretnymi metrykami i rezultatami
5. **FUTURE-PROOF**: Uwzglƒôdniaj emerging skills i adaptability

üî¨ PROCES OPTYMALIZACJI:
- **Krok 1**: Deep dive analiza oryginalnego CV i kontekstu stanowiska
- **Krok 2**: Identyfikacja gap'√≥w i opportunities dla improvement
- **Krok 3**: Strategic repositioning i value proposition enhancement
- **Krok 4**: Language optimization i professional storytelling
- **Krok 5**: ATS compatibility i human readability balance

‚ö° STANDARDY JAKO≈öCI:
- Jƒôzyk polski na poziomie native speaker z bran≈ºowƒÖ terminologiƒÖ
- Zero bullshit - ka≈ºde s≈Çowo ma konkretnƒÖ warto≈õƒá dodanƒÖ
- Authenticity over perfection - prawdziwe historie, nie marketing
- Actionable insights - konkretne kroki do implementacji
- ROI focus - ka≈ºda zmiana musi zwiƒôkszaƒá szanse na rozmowƒô

üí° SPECJALIZACJE BRAN≈ªOWE:
- **IT/Tech**: Techstack, metodologie (Agile, DevOps), impact na business
- **Finanse**: Compliance, risk management, analityka, certyfikaty
- **Sales/Marketing**: KPIs, conversion rates, customer acquisition
- **Healthcare**: Certyfikaty, patient outcomes, safety protocols
- **Przemys≈Ç**: Lean, Six Sigma, safety records, process optimization

Twoja misja: Ka≈ºde CV kt√≥re optymalizujesz ma zwiƒôkszyƒá szanse kandydata o minimum 40% w por√≥wnaniu do orygina≈Çu."""


# FUNKCJE DO ZARZƒÑDZANIA MODELAMI
def get_available_models():
    """Zwraca listƒô dostƒôpnych modeli AI"""
    return AVAILABLE_MODELS

def get_model_by_key(model_key):
    """Zwraca ID modelu na podstawie klucza"""
    logger.info(f"üîç DEBUG get_model_by_key: otrzymano model_key = {model_key}")
    logger.info(f"üîç DEBUG: dostƒôpne modele = {list(AVAILABLE_MODELS.keys())}")
    
    if model_key in AVAILABLE_MODELS:
        model_id = AVAILABLE_MODELS[model_key]["id"]
        logger.info(f"‚úÖ DEBUG: znaleziono model {model_key} -> {model_id}")
        return model_id
    
    logger.info(f"‚ùå DEBUG: nie znaleziono modelu {model_key}, u≈ºywam DEFAULT_MODEL = {DEFAULT_MODEL}")
    return DEFAULT_MODEL

def get_default_model():
    """Zwraca domy≈õlny model"""
    return DEFAULT_MODEL

# NOWE FUNKCJE INTELIGENTNEGO WYBORU MODELI

def get_best_model_for_task(task_type, is_premium=False, fallback_models=None):
    """
    üß† INTELIGENTNY WYB√ìR MODELU na podstawie typu zadania
    """
    # Mapa zada≈Ñ do preferowanych modeli
    task_model_map = {
        "optymalizacja_cv": ["qwen", "llama", "gpt4", "claude"],
        "analiza_jakosci": ["claude", "qwen", "gemini", "deepseek"], 
        "listy_motywacyjne": ["claude", "deepseek", "qwen", "gpt4"],
        "pytania_rekrutacyjne": ["gpt4", "deepseek", "gemini", "qwen"],
        "analiza_luk": ["claude", "gemini", "qwen", "deepseek"]
    }
    
    # Je≈õli u≈ºytkownik nie premium, preferuj darmowe modele
    if not is_premium:
        free_models = [key for key, model in AVAILABLE_MODELS.items() 
                      if model["id"].endswith(":free")]
        logger.info(f"üÜì Tryb darmowy - dostƒôpne modele: {free_models}")
    
    # Pobierz listƒô modeli dla tego zadania
    preferred_models = task_model_map.get(task_type, ["qwen", "deepseek"])
    
    # Filtruj tylko dostƒôpne modele
    for model_key in preferred_models:
        if model_key in AVAILABLE_MODELS:
            # Sprawd≈∫ czy model jest darmowy (je≈õli u≈ºytkownik nie premium)
            if not is_premium and not AVAILABLE_MODELS[model_key]["id"].endswith(":free"):
                continue
            logger.info(f"üéØ Wybrany najlepszy model dla {task_type}: {model_key}")
            return model_key
    
    # Fallback - zwr√≥ƒá pierwszy dostƒôpny darmowy model
    logger.info(f"‚ö†Ô∏è Nie znaleziono idealnego modelu dla {task_type}, u≈ºywam domy≈õlnego")
    return "qwen"  # Najbardziej uniwersalny

def get_adaptive_params(model_key, task_type, text_length=0):
    """
    ‚öôÔ∏è ADAPTACYJNE PARAMETRY dla r√≥≈ºnych modeli i zada≈Ñ
    """
    model_info = AVAILABLE_MODELS.get(model_key, AVAILABLE_MODELS["qwen"])
    base_params = model_info.get("optimal_params", {"temperature": 0.3, "top_p": 0.9})
    
    # Kopiuj bazowe parametry
    params = base_params.copy()
    
    # Dostosowania na podstawie typu zadania
    task_adjustments = {
        "optymalizacja_cv": {"frequency_penalty": 0.1, "presence_penalty": 0.1},
        "analiza_jakosci": {"temperature": params["temperature"] + 0.1, "frequency_penalty": 0.05},
        "listy_motywacyjne": {"temperature": params["temperature"] + 0.2, "presence_penalty": 0.2},
        "pytania_rekrutacyjne": {"temperature": params["temperature"] + 0.15, "frequency_penalty": 0.15},
        "analiza_luk": {"temperature": params["temperature"] - 0.05, "presence_penalty": 0.05}
    }
    
    # Zastosuj dostosowania
    if task_type in task_adjustments:
        params.update(task_adjustments[task_type])
    
    # Dostosowania na podstawie d≈Çugo≈õci tekstu
    if text_length > 5000:  # D≈Çugie teksty
        params["max_tokens"] = min(params.get("max_tokens", 3500) + 500, model_info.get("max_tokens", 4000))
    elif text_length < 1000:  # Kr√≥tkie teksty
        params["max_tokens"] = max(params.get("max_tokens", 3500) - 500, 2000)
    else:
        params["max_tokens"] = params.get("max_tokens", model_info.get("max_tokens", 3500))
    
    # Zapewnij ≈ºe parametry sƒÖ w prawid≈Çowych zakresach
    params["temperature"] = max(0.1, min(1.0, params["temperature"]))
    params["top_p"] = max(0.1, min(1.0, params["top_p"]))
    params["frequency_penalty"] = max(0.0, min(2.0, params.get("frequency_penalty", 0.1)))
    params["presence_penalty"] = max(0.0, min(2.0, params.get("presence_penalty", 0.1)))
    
    logger.info(f"‚öôÔ∏è Adaptacyjne parametry dla {model_key}/{task_type}: {params}")
    return params

def create_fallback_hierarchy(primary_model, task_type):
    """
    üîÑ TWORZENIE HIERARCHII FALLBACK MODELI
    """
    # Wszystkie modele posortowane wed≈Çug jako≈õci dla danego zadania
    model_hierarchy = {
        "optymalizacja_cv": ["qwen", "claude", "llama", "gpt4", "deepseek", "gemini"],
        "analiza_jakosci": ["claude", "qwen", "gemini", "gpt4", "deepseek", "llama"],
        "listy_motywacyjne": ["claude", "deepseek", "qwen", "gpt4", "gemini", "llama"],
        "pytania_rekrutacyjne": ["gpt4", "deepseek", "gemini", "claude", "qwen", "llama"],
        "analiza_luk": ["claude", "gemini", "qwen", "deepseek", "gpt4", "llama"]
    }
    
    hierarchy = model_hierarchy.get(task_type, ["qwen", "deepseek", "claude", "gpt4", "gemini", "llama"])
    
    # Przenie≈õ primary_model na poczƒÖtek je≈õli nie jest tam
    if primary_model in hierarchy:
        hierarchy.remove(primary_model)
    hierarchy.insert(0, primary_model)
    
    # Filtruj tylko dostƒôpne modele
    available_hierarchy = [model for model in hierarchy if model in AVAILABLE_MODELS]
    
    logger.info(f"üîÑ Hierarchia fallback dla {task_type}: {available_hierarchy}")
    return available_hierarchy


# üìä FUNKCJE MONITORINGU JAKO≈öCI AI

def record_response_metrics(model_id, task_type, response_time, success, quality_score=None, error_type=None):
    """
    üìà ZAPISZ METRYKI WYDAJNO≈öCI dla danego modelu i zadania
    """
    try:
        # Response time
        if len(_quality_metrics['response_times'][model_id]) >= MAX_METRICS_SIZE:
            _quality_metrics['response_times'][model_id].popleft()
        _quality_metrics['response_times'][model_id].append(response_time)
        
        # Success rate
        _quality_metrics['success_rates'][model_id].append(success)
        if len(_quality_metrics['success_rates'][model_id]) > MAX_METRICS_SIZE:
            _quality_metrics['success_rates'][model_id] = _quality_metrics['success_rates'][model_id][-MAX_METRICS_SIZE:]
        
        # Model usage
        _quality_metrics['model_usage'][model_id] += 1
        
        # Quality score if provided
        if quality_score is not None:
            if len(_quality_metrics['quality_scores'][model_id]) >= MAX_METRICS_SIZE:
                _quality_metrics['quality_scores'][model_id].popleft()
            _quality_metrics['quality_scores'][model_id].append(quality_score)
        
        # Error tracking
        if error_type:
            _quality_metrics['error_types'][error_type] += 1
        
        # Task performance
        _quality_metrics['task_performance'][task_type].append({
            'model': model_id,
            'success': success,
            'response_time': response_time,
            'timestamp': datetime.now()
        })
        
        # Ogranicz task performance
        if len(_quality_metrics['task_performance'][task_type]) > MAX_METRICS_SIZE:
            _quality_metrics['task_performance'][task_type] = _quality_metrics['task_performance'][task_type][-MAX_METRICS_SIZE:]
            
    except Exception as e:
        logger.warning(f"üìä B≈ÇƒÖd zapisywania metryk: {str(e)}")

def record_fallback_event(primary_model, fallback_model, task_type, reason):
    """
    üîÑ ZAPISZ WYDARZENIE FALLBACK
    """
    try:
        event = {
            'timestamp': datetime.now(),
            'primary_model': primary_model,
            'fallback_model': fallback_model,
            'task_type': task_type,
            'reason': reason
        }
        _quality_metrics['fallback_events'].append(event)
        
        # Ogranicz liczbƒô wydarze≈Ñ
        if len(_quality_metrics['fallback_events']) > MAX_METRICS_SIZE:
            _quality_metrics['fallback_events'] = _quality_metrics['fallback_events'][-MAX_METRICS_SIZE:]
            
        logger.info(f"üîÑ Fallback event: {primary_model} ‚Üí {fallback_model} dla {task_type}")
        
    except Exception as e:
        logger.warning(f"üîÑ B≈ÇƒÖd zapisywania fallback event: {str(e)}")

def get_model_performance_summary(model_id=None, hours=24):
    """
    üìä POBIERZ PODSUMOWANIE WYDAJNO≈öCI modeli z ostatnich X godzin
    """
    try:
        summary = {}
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        models_to_check = [model_id] if model_id else _quality_metrics['model_usage'].keys()
        
        for mid in models_to_check:
            if mid not in _quality_metrics['model_usage']:
                continue
                
            # Response times
            response_times = list(_quality_metrics['response_times'][mid])
            avg_response_time = statistics.mean(response_times) if response_times else 0
            
            # Success rate
            successes = _quality_metrics['success_rates'][mid]
            success_rate = (sum(successes) / len(successes) * 100) if successes else 0
            
            # Quality scores
            quality_scores = list(_quality_metrics['quality_scores'][mid])
            avg_quality = statistics.mean(quality_scores) if quality_scores else None
            
            # Usage count
            usage_count = _quality_metrics['model_usage'][mid]
            
            summary[mid] = {
                'avg_response_time': round(avg_response_time, 2),
                'success_rate': round(success_rate, 1),
                'avg_quality_score': round(avg_quality, 2) if avg_quality else None,
                'usage_count': usage_count,
                'total_requests': len(successes)
            }
        
        return summary
    
    except Exception as e:
        logger.error(f"üìä B≈ÇƒÖd generowania podsumowania wydajno≈õci: {str(e)}")
        return {}

def get_task_performance_insights(task_type=None, hours=24):
    """
    üéØ ANALIZA WYDAJNO≈öCI dla konkretnych typ√≥w zada≈Ñ
    """
    try:
        insights = {}
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        tasks_to_check = [task_type] if task_type else _quality_metrics['task_performance'].keys()
        
        for task in tasks_to_check:
            if task not in _quality_metrics['task_performance']:
                continue
                
            # Filtruj ostatnie X godzin
            recent_performances = [
                p for p in _quality_metrics['task_performance'][task]
                if p['timestamp'] > cutoff_time
            ]
            
            if not recent_performances:
                continue
            
            # Grupuj wed≈Çug modeli
            model_performance = defaultdict(list)
            for perf in recent_performances:
                model_performance[perf['model']].append(perf)
            
            # Analiza dla ka≈ºdego modelu
            task_insights = {}
            for model, performances in model_performance.items():
                success_rate = sum(p['success'] for p in performances) / len(performances) * 100
                avg_time = statistics.mean(p['response_time'] for p in performances)
                
                task_insights[model] = {
                    'success_rate': round(success_rate, 1),
                    'avg_response_time': round(avg_time, 2),
                    'total_requests': len(performances)
                }
            
            # Najlepszy model dla tego zadania
            if task_insights:
                best_model = max(task_insights.keys(), 
                               key=lambda m: (task_insights[m]['success_rate'], 
                                            -task_insights[m]['avg_response_time']))
                
                insights[task] = {
                    'model_performance': task_insights,
                    'recommended_model': best_model,
                    'total_requests': len(recent_performances)
                }
        
        return insights
    
    except Exception as e:
        logger.error(f"üéØ B≈ÇƒÖd analizy wydajno≈õci zada≈Ñ: {str(e)}")
        return {}

def assess_response_quality(response_text, task_type):
    """
    üîç SZYBKA OCENA JAKO≈öCI odpowiedzi (heurystyczna)
    """
    try:
        if not response_text or len(response_text.strip()) < 50:
            return 1.0  # Bardzo niska jako≈õƒá
        
        quality_score = 5.0  # Start z ≈õredniƒÖ ocenƒÖ
        
        # D≈Çugo≈õƒá odpowiedzi (optimal range zale≈ºy od typu zadania)
        optimal_lengths = {
            'optymalizacja_cv': (1000, 4000),
            'analiza_jakosci': (500, 2000),
            'listy_motywacyjne': (300, 800),
            'pytania_rekrutacyjne': (400, 1200),
            'analiza_luk': (600, 1500)
        }
        
        optimal_min, optimal_max = optimal_lengths.get(task_type, (500, 2000))
        length = len(response_text)
        
        if optimal_min <= length <= optimal_max:
            quality_score += 1.0
        elif length < optimal_min * 0.7 or length > optimal_max * 1.5:
            quality_score -= 1.0
        
        # Sprawd≈∫ czy zawiera oczekiwane elementy
        if task_type == 'optymalizacja_cv':
            if '--- STANOWISKO ---' in response_text:
                quality_score += 1.0
            if any(word in response_text.lower() for word in ['do≈õwiadczenie', 'umiejƒôtno≈õci', 'wykszta≈Çcenie']):
                quality_score += 0.5
        
        elif task_type == 'analiza_jakosci':
            if 'OCENA KO≈ÉCOWA:' in response_text or '/100' in response_text:
                quality_score += 1.0
            if any(word in response_text for word in ['MOCNE STRONY', 'OBSZARY DO POPRAWY']):
                quality_score += 0.5
        
        # Sprawd≈∫ czy nie zawiera b≈Çƒôd√≥w lub pustych odpowiedzi
        error_indicators = ['error', 'failed', 'sorry', 'cannot', 'unable']
        if any(indicator in response_text.lower() for indicator in error_indicators):
            quality_score -= 2.0
        
        # Normalizuj do skali 1-10
        quality_score = max(1.0, min(10.0, quality_score))
        
        return quality_score
    
    except Exception as e:
        logger.warning(f"üîç B≈ÇƒÖd oceny jako≈õci: {str(e)}")
        return 5.0  # Domy≈õlna ocena w przypadku b≈Çƒôdu


def make_openrouter_request(prompt,
                            model=None,
                            is_premium=False,
                            max_retries=3,
                            max_tokens=None,
                            use_streaming=False,
                            use_cache=True,
                            task_type="optymalizacja_cv"):
    """
    üöÄ ULEPSZONA FUNKCJA OBS≈ÅUGUJƒÑCA WYB√ìR MODELI AI Z INTELIGENTNYM FALLBACK
    """
    if not API_KEY_VALID:
        logger.error("API key is not valid")
        return None

    # üß† INTELIGENTNY WYB√ìR MODELU
    if model:
        primary_model = model
        model_to_use = get_model_by_key(model)
    else:
        # Automatyczny wyb√≥r najlepszego modelu dla zadania
        primary_model = get_best_model_for_task(task_type, is_premium)
        model_to_use = get_model_by_key(primary_model)
    
    # üîÑ TWORZENIE HIERARCHII FALLBACK
    fallback_models = create_fallback_hierarchy(primary_model, task_type)
    
    logger.info(f"üéØ G≈Ç√≥wny model: {model_to_use}, fallback: {fallback_models[1:3] if len(fallback_models) > 1 else []}")

    # üíæ SPRAWD≈π CACHE NAJPIERW (u≈ºywaj wszystkich modeli w kluczu dla lepszego cache)
    cache_key = get_cache_key(prompt, [get_model_by_key(m) for m in fallback_models], is_premium, task_type)

    if use_cache:
        cached_response = get_from_cache(cache_key)
        if cached_response:
            return cached_response

    # ‚öôÔ∏è ADAPTACYJNE PARAMETRY na podstawie modelu i zadania
    text_length = len(prompt)
    params = get_adaptive_params(primary_model, task_type, text_length)
    
    # Nadpisz max_tokens je≈õli podano explicite
    if max_tokens:
        params["max_tokens"] = max_tokens

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://cv-optimizer-pro.replit.app",
        "X-Title": "CV Optimizer Pro"
    }

    # üîÑ PR√ìBUJ Z HIERARCHIƒÑ FALLBACK MODELI + MONITORING
    start_time = time.time()
    
    for model_index, current_model_key in enumerate(fallback_models):
        current_model_id = get_model_by_key(current_model_key)
        model_start_time = time.time()
        
        # Aktualizuj parametry dla bie≈ºƒÖcego modelu
        current_params = get_adaptive_params(current_model_key, task_type, text_length)
        if max_tokens:
            current_params["max_tokens"] = max_tokens

        data = {
            "model": current_model_id,
            "messages": [{
                "role": "system",
                "content": DEEP_REASONING_PROMPT
            }, {
                "role": "user",
                "content": prompt
            }],
            **current_params
        }

        # Pr√≥buj z retry mechanism dla ka≈ºdego modelu
        for attempt in range(max_retries):
            try:
                if model_index > 0:  # Fallback model
                    logger.info(f"üîÑ Fallback do modelu {current_model_id} (pr√≥ba {attempt + 1}/{max_retries})")
                    # üìä Zapisz fallback event
                    if model_index == 1:  # Pierwszy fallback
                        primary_model_id = get_model_by_key(fallback_models[0])
                        record_fallback_event(primary_model_id, current_model_id, task_type, "primary_model_failed")
                else:  # Primary model
                    logger.info(f"üì° Wysy≈Çanie zapytania do {current_model_id} (pr√≥ba {attempt + 1}/{max_retries})")

                # ‚ö†Ô∏è KRYTYCZNY FIX: Robust HTTP timeouts + exponential backoff
                connection_timeout = 10  # Czas na nawiƒÖzanie po≈ÇƒÖczenia
                read_timeout = 30       # Czas na odczyt odpowiedzi
                
                response = session.post(OPENROUTER_BASE_URL,
                                        headers=headers,
                                        json=data,
                                        timeout=(connection_timeout, read_timeout),
                                        stream=use_streaming)
                
                # Sprawd≈∫ status i b≈Çƒôdy
                if response.status_code == 429:
                    # Rate limit - natychmiastowy fallback do nastƒôpnego modelu
                    logger.warning(f"üí∏ Rate limit (429) dla {current_model_id}, fallback")
                    response_time = time.time() - model_start_time
                    record_response_metrics(current_model_id, task_type, response_time, 
                                          success=False, error_type="rate_limit")
                    break  # Przejd≈∫ do nastƒôpnego modelu
                
                response.raise_for_status()

                result = response.json()

                if 'choices' in result and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content']
                    response_time = time.time() - model_start_time
                    
                    logger.info(
                        f"‚úÖ Model {current_model_id} zwr√≥ci≈Ç odpowied≈∫ (d≈Çugo≈õƒá: {len(content)} znak√≥w, czas: {response_time:.2f}s)"
                    )

                    # üìä OCENA JAKO≈öCI ODPOWIEDZI
                    quality_score = assess_response_quality(content, task_type)
                    
                    # üìä ZAPISZ METRYKI SUKCESU
                    record_response_metrics(
                        current_model_id, task_type, response_time, 
                        success=True, quality_score=quality_score
                    )

                    # üíæ ZAPISZ DO CACHE
                    if use_cache:
                        save_to_cache(cache_key, content, current_model_id)

                    return content
                else:
                    logger.warning(f"‚ö†Ô∏è Nieoczekiwany format odpowiedzi z {current_model_id}: {result}")
                    # üìä Zapisz b≈ÇƒÖd
                    response_time = time.time() - model_start_time
                    record_response_metrics(current_model_id, task_type, response_time, 
                                          success=False, error_type="invalid_response_format")
                    break  # Przejd≈∫ do nastƒôpnego modelu

            except requests.exceptions.Timeout:
                logger.warning(f"‚è∞ Timeout z modelem {current_model_id} na pr√≥bie {attempt + 1}")
                response_time = time.time() - model_start_time
                record_response_metrics(current_model_id, task_type, response_time, 
                                      success=False, error_type="timeout")

            except requests.exceptions.RequestException as e:
                logger.warning(f"üö´ B≈ÇƒÖd zapytania z {current_model_id} na pr√≥bie {attempt + 1}: {str(e)}")
                response_time = time.time() - model_start_time
                
                if "rate limit" in str(e).lower() or "quota" in str(e).lower():
                    logger.warning(f"üí∏ Rate limit dla {current_model_id}, przechodzƒô do fallback")
                    record_response_metrics(current_model_id, task_type, response_time, 
                                          success=False, error_type="rate_limit")
                    break  # Przejd≈∫ natychmiast do nastƒôpnego modelu
                else:
                    record_response_metrics(current_model_id, task_type, response_time, 
                                          success=False, error_type="api_error")

            except Exception as e:
                logger.warning(f"‚ùå Nieoczekiwany b≈ÇƒÖd z {current_model_id}: {str(e)}")
                response_time = time.time() - model_start_time
                record_response_metrics(current_model_id, task_type, response_time, 
                                      success=False, error_type="unexpected_error")

            # Op√≥≈∫nienie przed ponownƒÖ pr√≥bƒÖ z tym samym modelem
            if attempt < max_retries - 1:
                import time
                time.sleep(1.5 * (attempt + 1))  # ZwiƒôkszajƒÖce op√≥≈∫nienie

        # Je≈õli wszystkie pr√≥by z tym modelem zawiod≈Çy, przejd≈∫ do nastƒôpnego
        logger.warning(f"‚ùå Model {current_model_id} nie odpowiedzia≈Ç po {max_retries} pr√≥bach")

    # Je≈õli wszystkie modele z hierarchii zawiod≈Çy
    total_time = time.time() - start_time
    logger.error(f"‚ùå Wszystkie modele z hierarchii {fallback_models} zawiod≈Çy (ca≈Çkowity czas: {total_time:.2f}s)")
    return None


def optimize_cv(cv_text,
                job_title,
                job_description="",
                is_premium=False,
                payment_verified=False,
                selected_model=None):
    """
    Optymalizuje CV za pomocƒÖ OpenRouter AI (Claude 3.5 Sonnet) i formatuje w profesjonalnym szablonie HTML
    """
    prompt = f"""
üéØ ZADANIE OPTYMALIZACJI CV: Stanowisko "{job_title}"

Jako ekspert w rekrutacji i psychologii CV, przeprowadzisz STRATEGICZNƒÑ OPTYMALIZACJƒò tego CV, transformujƒÖc je w potƒô≈ºne narzƒôdzie do pozyskania rozmowy kwalifikacyjnej.

üìä DANE WEJ≈öCIOWE:
ORYGINALNE CV KANDYDATA:
{cv_text}

KONTEKST STANOWISKA:
{job_description}

üéØ STRATEGIA TRANSFORMACJI (KRYTYCZNE ZASADY):

**SEKCJA 1: PODSUMOWANIE ZAWODOWE** 
‚úÖ Stw√≥rz MAGNETYCZNE podsumowanie 2-3 zdania
‚úÖ POWO≈ÅAJ siƒô wy≈ÇƒÖcznie na fakty z oryginalnego CV
‚úÖ U≈ºyj POWER WORDS zwiƒÖzanych z bran≈ºƒÖ stanowiska
‚úÖ Podkre≈õl QUANTIFIABLE ACHIEVEMENTS je≈õli sƒÖ dostƒôpne
‚úÖ Zako≈Ñcz VALUE PROPOSITION - co kandydat wniesie do firmy

**SEKCJA 2: DO≈öWIADCZENIE ZAWODOWE** 
üö® OBOWIƒÑZKOWY FORMAT (nie odstƒôpuj!):
--- STANOWISKO ---
**[Nazwa stanowiska z impact keywords]**
**[Nazwa firmy]**
*[Okres pracy: MM/RRRR - MM/RRRR lub obecnie]*
- [Action verb] + [konkretny rezultat] + [impact na firmƒô/proces]
- [Action verb] + [wykorzystane narzƒôdzia/metodologie] + [osiƒÖgniƒôcie]
- [Action verb] + [wsp√≥≈Çpraca/leadership] + [measurable outcome]
- [Action verb] + [problem solving] + [business value]

üî• TRANSFORMATION RULES:
- Ka≈ºdy punkt zaczyna siƒô od IMPACT VERB (zarzƒÖdza≈Ç‚Üíoptymalizowa≈Ç, robi≈Ç‚Üíwprowadzi≈Ç)
- Dodaj LICZBY/METRYKI gdzie to mo≈ºliwe (zwiƒôkszy≈Ç o X%, zarzƒÖdza≈Ç zespo≈Çem X os√≥b)
- U≈ºyj BRAN≈ªOWYCH KEYWORDS z opisu stanowiska
- R√ì≈ªNICUJ opisy - nawet podobne stanowiska majƒÖ unikalne achievements
- MANDATORY: separator "--- STANOWISKO ---" przed KA≈ªDYM stanowiskiem

**SEKCJA 3: WYKSZTA≈ÅCENIE**
‚úÖ ZACHOWAJ oryginalnƒÖ strukturƒô i informacje
‚úÖ Dodaj RELEVANT COURSEWORK je≈õli istnieje zwiƒÖzek ze stanowiskiem
‚úÖ UPGRADE jƒôzyka - "uko≈Ñczy≈Ç"‚Üí"zdoby≈Ç dyplom", "uczy≈Ç siƒô"‚Üí"specjalizowa≈Ç siƒô"

**SEKCJA 4: UMIEJƒòTNO≈öCI**
‚úÖ KATEGORYZUJ logicznie: Techniczne | Soft Skills | Bran≈ºowe | Jƒôzykowe
‚úÖ PRIORYTETYZUJ umiejƒôtno≈õci wed≈Çug relevantno≈õci do stanowiska
‚úÖ U≈ªYJ TYLKO faktycznych umiejƒôtno≈õci z orygina≈Çu
‚úÖ UPGRADE terminologii (np. "obs≈Çuga komputera"‚Üí"zaawansowana znajomo≈õƒá pakietu Office")

‚ö†Ô∏è INTEGRITY GUARDRAILS:
üö´ ZERO fabricated information (stanowiska, daty, firmy, umiejƒôtno≈õci)
üö´ NO invented achievements or responsibilities  
üö´ NO false metrics or numbers
‚úÖ ONLY enhancement of existing authentic content
‚úÖ FACTUAL optimization with strategic language

üéØ OUTPUT REQUIREMENTS:
- POLISH NATIVE LEVEL z bran≈ºowƒÖ terminologiƒÖ
- READY-TO-USE format (≈ºadnych metadanych, komentarzy, JSON)
- ATS-FRIENDLY struktura z human appeal
- KA≈ªDE s≈Çowo musi mieƒá strategic purpose

Przekszta≈Çƒá to CV w INTERVIEW-WINNING document zachowujƒÖc 100% autentyczno≈õƒá!
    """

    # Rozszerzony limit token√≥w dla p≈ÇacƒÖcych u≈ºytkownik√≥w
    if is_premium or payment_verified:
        max_tokens = 4000
        prompt += f"""
        
    DODATKOWE INSTRUKCJE DLA U≈ªYTKOWNIK√ìW PREMIUM:
    - Stw√≥rz bardziej szczeg√≥≈Çowe opisy stanowisk (4-5 punkt√≥w zamiast 3-4)
    - Dodaj wiƒôcej s≈Ç√≥w kluczowych z bran≈ºy
    - Ulepszaj strukturƒô CV dla maksymalnej czytelno≈õci
    - Optymalizuj pod systemy ATS (Applicant Tracking Systems)
    """
    else:
        max_tokens = 2500

    try:
        # üéØ U≈ªYJ NOWEGO SYSTEMU INTELIGENTNEGO WYBORU MODELI
        response = make_openrouter_request(
            prompt,
            model=selected_model,
            is_premium=(is_premium or payment_verified),
            max_tokens=max_tokens,
            task_type="optymalizacja_cv"  # üß† Specyfikacja typu zadania
        )

        if response:
            # Zwr√≥ƒá zoptymalizowane CV jako sformatowany tekst
            # HTML bƒôdzie generowany dopiero przy wy≈õwietlaniu w view_cv
            logger.info(f"‚úÖ CV zoptymalizowane pomy≈õlnie (d≈Çugo≈õƒá: {len(response)} znak√≥w)")
            return response.strip()
        else:
            logger.error("‚ùå Brak odpowiedzi z API lub wszystkie modele zawiod≈Çy")
            return None

    except Exception as e:
        logger.error(f"‚ùå B≈ÇƒÖd w optimize_cv: {str(e)}")
        return None


def analyze_cv_quality(cv_text,
                       job_title,
                       job_description="",
                       is_premium=False,
                       selected_model=None):
    """
    Zaawansowana analiza jako≈õci CV z ocenƒÖ 0-100 punkt√≥w i szczeg√≥≈Çowymi wskaz√≥wkami AI
    """
    try:
        # Bardziej zaawansowany prompt dla lepszej analizy
        prompt = f"""
üéØ ZADANIE: Przeprowad≈∫ PROFESJONALNƒÑ ANALIZƒò JAKO≈öCI CV dla stanowiska "{job_title}"

üìã DANE WEJ≈öCIOWE:
CV DO ANALIZY:
{cv_text[:4000]}

OPIS STANOWISKA:
{job_description[:2000]}

üîç KRYTERIA OCENY (ka≈ºde 0-20 punkt√≥w):
1. **STRUKTURA I FORMATOWANIE** (0-20p)
   - Czytelno≈õƒá i organizacja sekcji
   - U≈ºycie w≈Ça≈õciwych nag≈Ç√≥wk√≥w
   - D≈Çugo≈õƒá i proporcje tre≈õci

2. **JAKO≈öƒÜ TRE≈öCI** (0-20p)
   - Konkretne osiƒÖgniƒôcia i wyniki
   - U≈ºycie liczb i metryk
   - Profesjonalizm opis√≥w

3. **DOPASOWANIE DO STANOWISKA** (0-20p)
   - Zgodno≈õƒá z wymaganiami
   - S≈Çowa kluczowe z oferty
   - Relevantne do≈õwiadczenie

4. **DO≈öWIADCZENIE I UMIEJƒòTNO≈öCI** (0-20p)
   - Progresja kariery
   - R√≥≈ºnorodno≈õƒá umiejƒôtno≈õci
   - Poziom senioratu

5. **KOMPLETNO≈öƒÜ I SZCZEG√ì≈ÅY** (0-20p)
   - Wszystkie potrzebne sekcje
   - Daty i okresy pracy
   - Informacje kontaktowe

üìä WYMAGANY FORMAT ODPOWIEDZI:
```
OCENA KO≈ÉCOWA: [0-100]/100

SZCZEG√ì≈ÅOWA PUNKTACJA:
‚Ä¢ Struktura i formatowanie: [0-20]/20
‚Ä¢ Jako≈õƒá tre≈õci: [0-20]/20  
‚Ä¢ Dopasowanie do stanowiska: [0-20]/20
‚Ä¢ Do≈õwiadczenie i umiejƒôtno≈õci: [0-20]/20
‚Ä¢ Kompletno≈õƒá i szczeg√≥≈Çy: [0-20]/20

üü¢ MOCNE STRONY:
- [minimum 3 konkretne punkty]

üü° OBSZARY DO POPRAWY:
- [minimum 3 konkretne sugestie]

üî• KLUCZOWE REKOMENDACJE:
- [3-5 najwa≈ºniejszych zmian do wprowadzenia]

üí° S≈ÅOWA KLUCZOWE DO DODANIA:
- [5-7 s≈Ç√≥w kluczowych z opisu stanowiska]

üéØ WSKAZ√ìWKI BRAN≈ªOWE:
- [2-3 specyficzne porady dla tej bran≈ºy/stanowiska]
```

‚úÖ DODATKOWE INSTRUKCJE:
- BƒÖd≈∫ konkretny i praktyczny
- Wska≈º dok≈Çadnie CO i GDZIE poprawiƒá
- Oce≈Ñ realistycznie ale konstruktywnie
- Napisz w jƒôzyku polskim
- U≈ºywaj emoji dla lepszej czytelno≈õci
"""

        # U≈ºyj lepszych parametr√≥w dla premium u≈ºytkownik√≥w
        max_tokens = 3000 if is_premium else 2000

        logger.info(f"üîç Analizowanie jako≈õci CV dla stanowiska: {job_title}")

        response = make_openrouter_request(
            prompt,
            model=selected_model,
            is_premium=is_premium,
            max_tokens=max_tokens,
            task_type="analiza_jakosci"  # üß† Specyfikacja typu zadania
        )

        if response:
            logger.info(
                f"‚úÖ Analiza CV uko≈Ñczona pomy≈õlnie (d≈Çugo≈õƒá: {len(response)} znak√≥w)"
            )
            return response.strip()
        else:
            logger.error("‚ùå Brak odpowiedzi z API lub nieprawid≈Çowa struktura")
            return None

    except Exception as e:
        logger.error(f"‚ùå B≈ÇƒÖd podczas analizy CV: {str(e)}")
        return None


def analyze_cv_with_score(cv_text,
                          job_title,
                          job_description="",
                          is_premium=False,
                          selected_model=None):
    """Zachowanie kompatybilno≈õci z istniejƒÖcym kodem - przekierowanie do nowej funkcji"""
    return analyze_cv_quality(cv_text, job_title, job_description, is_premium, selected_model)


def generate_cover_letter(cv_text,
                          job_title,
                          job_description="",
                          company_name="",
                          is_premium=False,
                          selected_model=None):
    """
    Generuje profesjonalny list motywacyjny na podstawie CV i opisu stanowiska u≈ºywajƒÖc AI
    """
    try:
        # Przygotowanie danych firmy
        company_info = f" w firmie {company_name}" if company_name else ""
        job_desc_info = f"\n\nOpis stanowiska:\n{job_description}" if job_description else ""

        prompt = f"""
    üéØ ZADANIE: Wygeneruj profesjonalny list motywacyjny w jƒôzyku polskim

    üìã DANE WEJ≈öCIOWE:
    ‚Ä¢ Stanowisko: {job_title}{company_info}
    ‚Ä¢ CV kandydata: {cv_text[:3000]}...{job_desc_info}

    ‚úÖ WYMAGANIA LISTU MOTYWACYJNEGO:
    1. Format profesjonalny (nag≈Ç√≥wek, zwroty grzeczno≈õciowe, podpis)
    2. D≈Çugo≈õƒá: 3-4 akapity (oko≈Ço 250-350 s≈Ç√≥w)
    3. Personalizacja pod konkretne stanowisko
    4. Podkre≈õlenie najwa≈ºniejszych kwalifikacji z CV
    5. Wykazanie motywacji i zaanga≈ºowania
    6. Profesjonalny, ale ciep≈Çy ton komunikacji

    üìù STRUKTURA LISTU:
    1. **Nag≈Ç√≥wek** - data, zwrot grzeczno≈õciowy
    2. **Wstƒôp** - przedstawienie siƒô i cel listu
    3. **G≈Ç√≥wna czƒô≈õƒá** - kwalifikacje, do≈õwiadczenie, motywacja
    4. **Zako≈Ñczenie** - zaproszenie do kontaktu, podziƒôkowania
    5. **Podpis** - zwroty ko≈Ñcowe

    üöÄ DODATKOWE WSKAZ√ìWKI:
    ‚Ä¢ U≈ºyj konkretnych przyk≈Çad√≥w z CV
    ‚Ä¢ Dostosuj ton do bran≈ºy i stanowiska
    ‚Ä¢ Podkre≈õl warto≈õƒá, jakƒÖ kandydat wniesie do firmy
    ‚Ä¢ Unikaj powtarzania informacji z CV - uzupe≈Çnij je
    ‚Ä¢ Zachowaj autentyczno≈õƒá i profesjonalizm

    Wygeneruj teraz kompletny list motywacyjny:
            """

        logger.info(
            f"üìß Generowanie listu motywacyjnego dla stanowiska: {job_title}")

        cover_letter = make_openrouter_request(
            prompt, 
            model=selected_model, 
            is_premium=is_premium,
            task_type="listy_motywacyjne"  # üß† Specyfikacja typu zadania
        )

        if cover_letter:
            logger.info(
                f"‚úÖ List motywacyjny wygenerowany pomy≈õlnie (d≈Çugo≈õƒá: {len(cover_letter)} znak√≥w)"
            )

            return {
                'success': True,
                'cover_letter': cover_letter,
                'job_title': job_title,
                'company_name': company_name,
                'model_used': selected_model or DEFAULT_MODEL
            }
        else:
            logger.error("‚ùå Brak odpowiedzi z API lub nieprawid≈Çowa struktura")
            return None

    except Exception as e:
        logger.error(
            f"‚ùå B≈ÇƒÖd podczas generowania listu motywacyjnego: {str(e)}")
        return None


def generate_interview_questions(cv_text,
                                 job_title,
                                 job_description="",
                                 is_premium=False,
                                 selected_model=None):
    """
    Generuje personalizowane pytania na rozmowƒô kwalifikacyjnƒÖ na podstawie CV i opisu stanowiska
    """
    try:
        job_desc_info = f"\n\nOpis stanowiska:\n{job_description}" if job_description else ""

        prompt = f"""
    üéØ ZADANIE: Wygeneruj personalizowane pytania na rozmowƒô kwalifikacyjnƒÖ w jƒôzyku polskim

    üìã DANE WEJ≈öCIOWE:
    ‚Ä¢ Stanowisko: {job_title}
    ‚Ä¢ CV kandydata: {cv_text[:3000]}...{job_desc_info}

    ‚úÖ WYMAGANIA PYTA≈É:
    1. 10-15 pyta≈Ñ dostosowanych do profilu kandydata
    2. Pytania powinny byƒá r√≥≈ºnorodne: techniczne, behawioralne, sytuacyjne
    3. Uwzglƒôdnij do≈õwiadczenie i umiejƒôtno≈õci z CV
    4. Dodaj pytania specyficzne dla bran≈ºy i stanowiska
    5. Uwzglƒôdnij poziom do≈õwiadczenia kandydata

    üìù KATEGORIE PYTA≈É:
    1. **Pytania podstawowe** - o do≈õwiadczeniu i motywacji
    2. **Pytania techniczne** - o konkretne umiejƒôtno≈õci z CV
    3. **Pytania behawioralne** - o sytuacje i zachowania
    4. **Pytania sytuacyjne** - scenariusze problemowe
    5. **Pytania o firmƒô** - zainteresowanie pozycjƒÖ i firmƒÖ

    üé§ FORMAT ODPOWIEDZI:
    PYTANIA PODSTAWOWE:
    1. [pytanie]
    2. [pytanie]

    PYTANIA TECHNICZNE:
    1. [pytanie]
    2. [pytanie]

    PYTANIA BEHAWIORALNE:
    1. [pytanie]
    2. [pytanie]

    PYTANIA SYTUACYJNE:
    1. [pytanie]
    2. [pytanie]

    PYTANIA O FIRMƒò I STANOWISKO:
    1. [pytanie]
    2. [pytanie]

    üöÄ WSKAZ√ìWKI:
    ‚Ä¢ Ka≈ºde pytanie powinno byƒá konkretne i merytoryczne
    ‚Ä¢ Uwzglƒôdnij s≈Çowa kluczowe z opisu stanowiska
    ‚Ä¢ Dostosuj poziom trudno≈õci do do≈õwiadczenia kandydata
    ‚Ä¢ Dodaj pytania sprawdzajƒÖce soft skills

    Wygeneruj teraz personalizowane pytania na rozmowƒô kwalifikacyjnƒÖ:
            """

        logger.info(
            f"ü§î Generowanie pyta≈Ñ na rozmowƒô dla stanowiska: {job_title}")

        questions = make_openrouter_request(
            prompt, 
            model=selected_model, 
            is_premium=is_premium,
            task_type="pytania_rekrutacyjne"  # üß† Specyfikacja typu zadania
        )

        if questions:
            logger.info(
                f"‚úÖ Pytania na rozmowƒô wygenerowane pomy≈õlnie (d≈Çugo≈õƒá: {len(questions)} znak√≥w)"
            )

            return {
                'success': True,
                'questions': questions,
                'job_title': job_title,
                'model_used': selected_model or DEFAULT_MODEL
            }
        else:
            logger.error("‚ùå Brak odpowiedzi z API lub nieprawid≈Çowa struktura")
            return None

    except Exception as e:
        logger.error(f"‚ùå B≈ÇƒÖd podczas generowania pyta≈Ñ na rozmowƒô: {str(e)}")
        return None


def analyze_skills_gap(cv_text,
                       job_title,
                       job_description="",
                       is_premium=False,
                       selected_model=None):
    """
    Analizuje luki kompetencyjne miƒôdzy CV a wymaganiami stanowiska
    """
    try:
        job_desc_info = f"\n\nOpis stanowiska:\n{job_description}" if job_description else ""

        prompt = f"""
    üéØ ZADANIE: Przeprowad≈∫ szczeg√≥≈ÇowƒÖ analizƒô luk kompetencyjnych w jƒôzyku polskim

    üìã DANE WEJ≈öCIOWE:
    ‚Ä¢ Stanowisko: {job_title}
    ‚Ä¢ CV kandydata: {cv_text[:3000]}...{job_desc_info}

    ‚úÖ CELE ANALIZY:
    1. Por√≥wnaj umiejƒôtno≈õci z CV z wymaganiami stanowiska
    2. Zidentyfikuj mocne strony kandydata
    3. Wykryj luki kompetencyjne i brakujƒÖce umiejƒôtno≈õci
    4. Zasugeruj sposoby rozwoju i uzupe≈Çnienia brak√≥w
    5. Oce≈Ñ og√≥lne dopasowanie do stanowiska (0-100%)

    üìä FORMAT ODPOWIEDZI:

    OCENA OG√ìLNA: [XX]% dopasowania do stanowiska

    MOCNE STRONY KANDYDATA:
    ‚úÖ [umiejƒôtno≈õƒá 1] - [kr√≥tkie uzasadnienie]
    ‚úÖ [umiejƒôtno≈õƒá 2] - [kr√≥tkie uzasadnienie]
    ‚úÖ [umiejƒôtno≈õƒá 3] - [kr√≥tkie uzasadnienie]

    LUKI KOMPETENCYJNE:
    ‚ùå [brakujƒÖca umiejƒôtno≈õƒá 1] - [dlaczego jest potrzebna]
    ‚ùå [brakujƒÖca umiejƒôtno≈õƒá 2] - [dlaczego jest potrzebna]
    ‚ùå [brakujƒÖca umiejƒôtno≈õƒá 3] - [dlaczego jest potrzebna]

    REKOMENDACJE ROZWOJU:
    üéì [konkretna rekomendacja 1] - [kurs/certyfikat/do≈õwiadczenie]
    üéì [konkretna rekomendacja 2] - [kurs/certyfikat/do≈õwiadczenie]
    üéì [konkretna rekomendacja 3] - [kurs/certyfikat/do≈õwiadczenie]

    PRIORYTET ROZWOJU:
    üî• WYSOKI PRIORYTET: [umiejƒôtno≈õci kluczowe dla stanowiska]
    üî∏ ≈öREDNI PRIORYTET: [umiejƒôtno≈õci przydatne]
    üîπ NISKI PRIORYTET: [umiejƒôtno≈õci dodatkowe]

    PLAN DZIA≈ÅANIA (3-6 miesiƒôcy):
    1. [konkretny krok do podjƒôcia]
    2. [konkretny krok do podjƒôcia]
    3. [konkretny krok do podjƒôcia]

    üöÄ WSKAZ√ìWKI:
    ‚Ä¢ Skup siƒô na umiejƒôtno≈õciach technicznych i soft skills
    ‚Ä¢ Uwzglƒôdnij trendy w bran≈ºy
    ‚Ä¢ Zasugeruj konkretne zasoby edukacyjne
    ‚Ä¢ Oce≈Ñ realno≈õƒá pozyskania brakujƒÖcych kompetencji

    Przeprowad≈∫ teraz szczeg√≥≈ÇowƒÖ analizƒô luk kompetencyjnych:
            """

        logger.info(
            f"üîç Analiza luk kompetencyjnych dla stanowiska: {job_title}")

        analysis = make_openrouter_request(
            prompt, 
            model=selected_model, 
            is_premium=is_premium,
            task_type="analiza_luk"  # üß† Specyfikacja typu zadania
        )

        if analysis:
            logger.info(
                f"‚úÖ Analiza luk kompetencyjnych uko≈Ñczona pomy≈õlnie (d≈Çugo≈õƒá: {len(analysis)} znak√≥w)"
            )

            return {
                'success': True,
                'analysis': analysis,
                'job_title': job_title,
                'model_used': selected_model or DEFAULT_MODEL
            }
        else:
            logger.error("‚ùå Brak odpowiedzi z API lub nieprawid≈Çowa struktura")
            return None

    except Exception as e:
        logger.error(f"‚ùå B≈ÇƒÖd podczas analizy luk kompetencyjnych: {str(e)}")
        return None
